LargeSort
=========
Код не совсем красивый, но основной подход к решению поставленной задачи полноценно отражает. 
А код, как известно, доводить до идеала можно бесконечно.

Максимальное количество используемой памяти указывается в константе MAX_MEMORY_USAGE_GB в Гб.
Файл, который необходимо отсортировать, оказывается в константе FILE_TO_SORT.

Фактически при максимальной загрузке памяти будет использоваться совсем немногим больше, т.к. не учитывал место под локальные переменные, указатели. 
Надеюсь, что это не столь критично в данном тесте.

Принцип работы основан на External Sort алгоритме:
Разбиваем входной файл на несколько отсортированных кусков по M Гб, 
где M - ограничение размера оперативной памяти.
Далее производим смешивание данных кусков файлав в один результирующий файл, используя Merge Sort алгоритм.
Результирующий файл сохраняется с постфиксом ".Sorted".

Для ускорения смешивания сортированных кусков в память читаются только ключи по 64 байта, а не записи целиком. 
Только после нахождения наименьшего ключа целая запись будет скопирована в память и отправлена в результирующий файл.
	
При ограничении памяти в 8 Гб максимальный размер входного файла практически не ограничен (~ 1 эксабайт) и
будет зависеть уже от внешних факторов (например, максимально возможное количество одновременно открытых файлов одним процессом).
